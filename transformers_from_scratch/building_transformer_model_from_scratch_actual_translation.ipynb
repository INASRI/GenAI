{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "H_Y6gmGa6vuM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the scaled dot-product attention\n",
        "def scaled_dot_product_attention(query, key, value, mask=None):\n",
        "    d_k = query.size(-1)\n",
        "    scores = torch.matmul(query, key.transpose(-2, -1)) / torch.sqrt(torch.tensor(d_k, dtype=torch.float32))\n",
        "    if mask is not None:\n",
        "        scores = scores.masked_fill(mask == 0, -1e9)\n",
        "    attention_weights = torch.nn.functional.softmax(scores, dim=-1)\n",
        "    output = torch.matmul(attention_weights, value)\n",
        "    return output, attention_weights\n",
        "\n",
        "# Define the multi-head attention module\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "        self.d_k = d_model // num_heads\n",
        "\n",
        "        self.query = nn.Linear(d_model, d_model)\n",
        "        self.key = nn.Linear(d_model, d_model)\n",
        "        self.value = nn.Linear(d_model, d_model)\n",
        "        self.out = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        batch_size = query.size(0)\n",
        "\n",
        "        def split_heads(x):\n",
        "            return x.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "        query = split_heads(self.query(query))\n",
        "        key = split_heads(self.key(key))\n",
        "        value = split_heads(self.value(value))\n",
        "\n",
        "        attention_output, _ = scaled_dot_product_attention(query, key, value, mask)\n",
        "        attention_output = attention_output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
        "        return self.out(attention_output)"
      ],
      "metadata": {
        "id": "pC4K-xiP6zx7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the feedforward network\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear2(self.relu(self.linear1(x)))"
      ],
      "metadata": {
        "id": "UxS862Kp62M8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define positional encoding\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(np.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]"
      ],
      "metadata": {
        "id": "VcYwcoTa65cD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Transformer block\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.attention = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = FeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        attn_output = self.dropout(self.attention(x, x, x, mask))\n",
        "        x = self.norm1(x + attn_output)\n",
        "        ff_output = self.dropout(self.feed_forward(x))\n",
        "        x = self.norm2(x + ff_output)\n",
        "        return x"
      ],
      "metadata": {
        "id": "qbbUT00h6_Lq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Transformer model\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, input_vocab_size, target_vocab_size, d_model, num_heads, d_ff, num_layers, max_len=100, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.encoder_embedding = nn.Embedding(input_vocab_size, d_model)\n",
        "        self.decoder_embedding = nn.Embedding(target_vocab_size, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model, max_len)\n",
        "        self.encoder_layers = nn.ModuleList([TransformerBlock(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.decoder_layers = nn.ModuleList([TransformerBlock(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.fc_out = nn.Linear(d_model, target_vocab_size)\n",
        "\n",
        "    def forward(self, src, trg, src_mask=None, trg_mask=None):\n",
        "        # Encoder\n",
        "        src = self.encoder_embedding(src)\n",
        "        src = self.positional_encoding(src)\n",
        "        for layer in self.encoder_layers:\n",
        "            src = layer(src, src_mask)\n",
        "\n",
        "        # Decoder\n",
        "        trg = self.decoder_embedding(trg)\n",
        "        trg = self.positional_encoding(trg)\n",
        "        for layer in self.decoder_layers:\n",
        "            trg = layer(trg, trg_mask)\n",
        "\n",
        "        # Output layer\n",
        "        return self.fc_out(trg)"
      ],
      "metadata": {
        "id": "XL9jxwYE7DVD"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters\n",
        "INPUT_VOCAB_SIZE = tokenizer.vocab_size  # Use the tokenizer's vocabulary size\n",
        "TARGET_VOCAB_SIZE = tokenizer.vocab_size # Use the tokenizer's vocabulary size\n",
        "D_MODEL = 512\n",
        "NUM_HEADS = 8\n",
        "D_FF = 2048\n",
        "NUM_LAYERS = 6\n",
        "MAX_LEN = 100\n",
        "\n",
        "# Instantiate the model with the updated vocabulary size\n",
        "model = Transformer(INPUT_VOCAB_SIZE, TARGET_VOCAB_SIZE, D_MODEL, NUM_HEADS, D_FF, NUM_LAYERS, MAX_LEN)"
      ],
      "metadata": {
        "id": "mhikhzKr6pXN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example input (batch of tokenized sequences)\n",
        "src = torch.randint(0, INPUT_VOCAB_SIZE, (32, 10))  # Source batch (batch_size=32, seq_len=10)\n",
        "trg = torch.randint(0, TARGET_VOCAB_SIZE, (32, 10))  # Target batch (batch_size=32, seq_len=10)\n"
      ],
      "metadata": {
        "id": "AqCTsPF77MIM"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Forward pass\n",
        "output = model(src, trg)\n",
        "print(output.shape)  # Should be (batch_size, seq_len, target_vocab_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2Q92p-67TGD",
        "outputId": "4f3869df-55c0-42f9-c282-c7fc453530b1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 10, 50257])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and Testing\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, src_data, trg_data, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src_data, trg_data[:, :-1])\n",
        "        output = output.reshape(-1, output.shape[-1])\n",
        "        trg = trg_data[:, 1:].reshape(-1)\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "NDxryoQc9PFU"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate dummy data\n",
        "src_data = torch.randint(0, INPUT_VOCAB_SIZE, (32, 20))\n",
        "trg_data = torch.randint(0, TARGET_VOCAB_SIZE, (32, 20))\n",
        "\n",
        "# Train the model\n",
        "train_model(model, src_data, trg_data, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqDFNVzU9S7c",
        "outputId": "5ba2f057-3134-4d6b-bf31-9f3a266e72bc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 10.9932\n",
            "Epoch 2/5, Loss: 10.6207\n",
            "Epoch 3/5, Loss: 10.3270\n",
            "Epoch 4/5, Loss: 10.0739\n",
            "Epoch 5/5, Loss: 9.8452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple test for translation\n",
        "def translate(model, src_sentence):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        src = torch.tensor(src_sentence).unsqueeze(0)\n",
        "        trg = torch.zeros((1, MAX_LEN), dtype=torch.long)\n",
        "        for i in range(1, MAX_LEN):\n",
        "            output = model(src, trg[:, :i])\n",
        "            next_word = output.argmax(dim=-1)[:, -1]\n",
        "            trg[0, i] = next_word\n",
        "            if next_word.item() == 1:  # Assuming 1 is the <eos> token\n",
        "                break\n",
        "        return trg.squeeze().tolist()"
      ],
      "metadata": {
        "id": "FDk4qU5L9Zrb"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test translation\n",
        "src_sentence = [5, 20, 30, 40, 50, 60, 70]  # Example tokenized source sentence\n",
        "translation = translate(model, src_sentence)\n",
        "print(\"Translated Sentence:\", translation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xEJXYqF9MDr",
        "outputId": "9e041d8d-853e-4b6a-dee2-79822fd74ade"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated Sentence: [0, 4241, 1693, 25313, 42242, 20346, 11910, 5752, 25313, 25313, 25313, 25313, 25313, 25313, 25313, 25313, 43823, 34602, 36845, 18472, 30890, 13507, 37825, 11602, 29366, 20346, 7740, 35066, 21591, 45528, 18472, 34654, 14232, 24051, 24494, 18706, 48922, 28370, 48922, 34028, 18472, 3412, 15690, 23014, 44888, 17206, 41055, 38348, 40887, 226, 38677, 20121, 35410, 9313, 11374, 35410, 9313, 11374, 7264, 8114, 8323, 8165, 35181, 34602, 40360, 6353, 25542, 25313, 30778, 25745, 48922, 12449, 17953, 34809, 584, 13487, 34602, 25745, 41115, 6990, 8868, 37208, 27739, 45528, 16341, 35657, 31342, 35657, 37722, 621, 24803, 31342, 35657, 23187, 16308, 5421, 23187, 35657, 14776, 36837]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Use a pre-trained tokenizer (e.g., GPT-2 tokenizer)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
      ],
      "metadata": {
        "id": "sbAcaK-9BP88"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example sentences\n",
        "source_sentence = \"hello world\"\n",
        "target_sentence = \"bonjour le monde\"\n",
        "\n",
        "# Tokenize and encode the sentences\n",
        "src_tokens = tokenizer.encode(source_sentence, return_tensors=\"pt\")\n",
        "trg_tokens = tokenizer.encode(target_sentence, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "6NSiiajFBWD7"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training example\n",
        "train_model(model, src_tokens.repeat(32, 1), trg_tokens.repeat(32, 1), epochs=5)\n",
        "\n",
        "# Translate a sentence\n",
        "translated_tokens = translate(model, src_tokens.squeeze().tolist())\n",
        "translated_sentence = tokenizer.decode(translated_tokens, skip_special_tokens=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNvv9GiWBLjN",
        "outputId": "10e2bdd0-f381-4039-a456-21d0b6012ebc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 11.1919\n",
            "Epoch 2/5, Loss: 9.4892\n",
            "Epoch 3/5, Loss: 7.5151\n",
            "Epoch 4/5, Loss: 5.8527\n",
            "Epoch 5/5, Loss: 4.5456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Source Sentence:\", source_sentence)\n",
        "print(\"Translated Sentence:\", translated_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9WHkgX7BZYE",
        "outputId": "b1262702-755f-44ea-b09d-5979b0da75b4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source Sentence: hello world\n",
            "Translated Sentence: !our le mondeour le mondeour le mondeour le mondeour le mondeour le mondeour le mondeour le mondeour le mondeondeour le mondeondeondeour le mondeour le mondeour le mondeour le mondeour le mondeour le mondeour le mondeour le mondeour le mondeour le mondeour le mondeour le mondeour le mondeour le monde\n"
          ]
        }
      ]
    }
  ]
}