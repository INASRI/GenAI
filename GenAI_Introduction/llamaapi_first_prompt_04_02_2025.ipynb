{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wCgfK3GoqYeq"
   },
   "outputs": [],
   "source": [
    "!pip install llamaapi -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4T5k0mLYqmv8"
   },
   "outputs": [],
   "source": [
    "from llamaapi import LlamaAPI\n",
    "import json\n",
    "\n",
    "# Replace 'Your_API_Token' with your actual API token\n",
    "llama = LlamaAPI('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SvsBHyi9rVmi",
    "outputId": "d13c952a-c511-4946-b59d-c42ef680b62d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"created\": 1713352204,\n",
      "  \"model\": \"llama-13b-chat\",\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 24,\n",
      "    \"completion_tokens\": 66,\n",
      "    \"total_tokens\": 90\n",
      "  },\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Llama llama ding dong, happy llama day to you, my llama friend! Llama llama chuff chuff, how may I assist you today? Llama llama woolly wool, do you have any llama-related questions or requests? Llama llama spit spit, let me know and I'll do my best to help!\",\n",
      "        \"function_call\": null\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# API Request JSON Cell\n",
    "api_request_json = {\n",
    "  \"model\": \"llama-13b-chat\",\n",
    "  \"messages\": [\n",
    "    {\"role\": \"system\", \"content\": \"You are a llama assistant that talks like a llama, starting every word with 'll'.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hi, happy llama day!\"},\n",
    "  ]\n",
    "}\n",
    "\n",
    "# Make your request and handle the response\n",
    "response = llama.run(api_request_json)\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hAhFpjI046AH",
    "outputId": "59f754ea-ca7c-4344-ea27-917b9d447ac9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"created\": 1713359777,\n",
      "  \"model\": \"llama-13b-chat\",\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 20,\n",
      "    \"completion_tokens\": 117,\n",
      "    \"total_tokens\": 137\n",
      "  },\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Sure, Jennifer Lopez, also known as J.Lo, is a multi-talented American actress, singer, dancer, and producer. She has had a successful career in the entertainment industry spanning over two decades, with notable roles in films such as \\\"Selena\\\" and \\\"Maid in Manhattan,\\\" as well as hit songs like \\\"If You Had My Love\\\" and \\\"Love Don't Cost a Thing.\\\" She has also been a judge on the reality TV show \\\"American Idol\\\" and has been recognized for her philanthropic work, particularly in support of Latino and women's issues.\",\n",
      "        \"function_call\": null\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# API Request JSON Cell\n",
    "api_request_json = {\n",
    "  \"model\": \"llama-13b-chat\",\n",
    "  \"messages\": [\n",
    "    {\"role\": \"system\", \"content\": \"Just answer the question below\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who is Jennifer Lopez and can you provide me a few sentences about the artist\"},\n",
    "  ]\n",
    "}\n",
    "\n",
    "# Make your request and handle the response\n",
    "response = llama.run(api_request_json)\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
